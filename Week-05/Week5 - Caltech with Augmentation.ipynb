{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Step1: Data Preparing`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "original_dataset_dir = '/caltech101-dataset/dataset-balanced/'\n",
    "base_dir = '/caltech101-dataset/balanced-dataset-final/'\n",
    "\n",
    "if not(os.path.exists(base_dir)):\n",
    "    os.mkdir(base_dir)\n",
    "    \n",
    "# getting all labels\n",
    "labels = os.listdir(original_dataset_dir)\n",
    "\n",
    "# Creating labels folders in balanced dataset\n",
    "'''\n",
    "for i in range(len(labels)):\n",
    "    if not(os.path.exists(base_dir + labels[i])):\n",
    "        os.mkdir(base_dir + labels[i])\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Balancing Data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from scipy import ndarray\n",
    "\n",
    "# image processing library\n",
    "import skimage as sk\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "from skimage import io\n",
    "\n",
    "def random_rotation(image_array: ndarray):\n",
    "    # pick a random degree of rotation between 25% on the left and 25% on the right\n",
    "    random_degree = random.uniform(-25, 25)\n",
    "    return sk.transform.rotate(image_array, random_degree)\n",
    "\n",
    "def random_noise(image_array: ndarray):\n",
    "    # add random noise to the image\n",
    "    return sk.util.random_noise(image_array)\n",
    "\n",
    "def horizontal_flip(image_array: ndarray):\n",
    "    # horizontal flip doesn't need skimage, it's easy as flipping the image array of pixels !\n",
    "    return image_array[:, ::-1]\n",
    "\n",
    "# dictionary of the transformations we defined earlier\n",
    "available_transformations = {\n",
    "    'rotate': random_rotation,\n",
    "    'noise': random_noise,\n",
    "    'horizontal_flip': horizontal_flip\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_instances_per_class = 1000 # Total images per class required\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    label_path = original_dataset_dir + labels[i]\n",
    "    new_label_path = base_dir + labels[i]\n",
    "    \n",
    "    num_files_desired = total_instances_per_class - len(os.listdir(label_path))\n",
    "\n",
    "    # find all files paths from the folder\n",
    "    images = [os.path.join(label_path, f) for f in os.listdir(label_path) \n",
    "              if os.path.isfile(os.path.join(label_path, f))]\n",
    "    \n",
    "    #print(len(images))\n",
    "        \n",
    "    num_generated_files = 0\n",
    "    while num_generated_files <= num_files_desired:\n",
    "        \n",
    "        image_path = random.choice(images) # choose random image from folder\n",
    "        # read image as an two dimensional array of pixels\n",
    "        image_to_transform = sk.io.imread(image_path)\n",
    "        # random num of transformation to apply\n",
    "        num_transformations_to_apply = random.randint(1, len(available_transformations))\n",
    "\n",
    "        num_transformations = 0\n",
    "        transformed_image = None\n",
    "        while num_transformations <= num_transformations_to_apply:\n",
    "            # random transformation to apply for a single image\n",
    "            key = random.choice(list(available_transformations))\n",
    "            transformed_image = available_transformations[key](image_to_transform)\n",
    "            num_transformations += 1\n",
    "\n",
    "        new_file_path = '%s/augmented_image_%s.jpg' % (label_path, num_generated_files)\n",
    "\n",
    "        # write image to the disk\n",
    "        io.imsave(new_file_path, transformed_image)\n",
    "        num_generated_files += 1\n",
    "        \n",
    "        print((i+1), new_file_path, labels[i], num_files_desired)    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from scipy import ndarray\n",
    "\n",
    "# image processing library\n",
    "import skimage as sk\n",
    "from skimage import transform\n",
    "from skimage import util\n",
    "from skimage import io\n",
    "\n",
    "def random_rotation(image_array: ndarray):\n",
    "    # pick a random degree of rotation between 25% on the left and 25% on the right\n",
    "    random_degree = random.uniform(-25, 25)\n",
    "    return sk.transform.rotate(image_array, random_degree)\n",
    "\n",
    "def random_noise(image_array: ndarray):\n",
    "    # add random noise to the image\n",
    "    return sk.util.random_noise(image_array)\n",
    "\n",
    "def horizontal_flip(image_array: ndarray):\n",
    "    # horizontal flip doesn't need skimage, it's easy as flipping the image array of pixels !\n",
    "    return image_array[:, ::-1]\n",
    "\n",
    "# dictionary of the transformations we defined earlier\n",
    "available_transformations = {\n",
    "    'rotate': random_rotation,\n",
    "    'noise': random_noise,\n",
    "    'horizontal_flip': horizontal_flip\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "folder_path = 'images/cat'\n",
    "num_files_desired = 10\n",
    "\n",
    "# find all files paths from the folder\n",
    "images = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]\n",
    "\n",
    "num_generated_files = 0\n",
    "while num_generated_files <= num_files_desired:\n",
    "    # random image from the folder\n",
    "    image_path = random.choice(images)\n",
    "    # read image as an two dimensional array of pixels\n",
    "    image_to_transform = sk.io.imread(image_path)\n",
    "    # random num of transformation to apply\n",
    "    num_transformations_to_apply = random.randint(1, len(available_transformations))\n",
    "\n",
    "    num_transformations = 0\n",
    "    transformed_image = None\n",
    "    while num_transformations <= num_transformations_to_apply:\n",
    "        # random transformation to apply for a single image\n",
    "        key = random.choice(list(available_transformations))\n",
    "        transformed_image = available_transformations[key](image_to_transform)\n",
    "        num_transformations += 1\n",
    "\n",
    "new_file_path = '%s/augmented_image_%s.jpg' % (folder_path, num_generated_files)\n",
    "\n",
    "# write image to the disk\n",
    "io.imsave(new_file_path, transformed_image)\n",
    "num_generated_files += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose one option:\n",
      "0- For Whole Dataset\n",
      "2- For Specifying minimum classes\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "\n",
    "total_classes = []\n",
    "train_data = []\n",
    "validation_data = []\n",
    "test_data = []\n",
    "\n",
    "original_dataset_dir = '../caltech101-dataset'\n",
    "base_dir = '../caltech101-dataset'\n",
    "dir_custom = '/caltech101-dataset/dataset-'\n",
    "\n",
    "print(\"Choose one option:\\n0- For Whole Dataset\\n2- For Specifying minimum classes\")\n",
    "min_instances = int(input())\n",
    "\n",
    "if (not(os.path.exists(base_dir)) and min_instances == 0):\n",
    "    os.mkdir(base_dir)\n",
    "\n",
    "elif not(os.path.exists((dir_custom + str(min_instances)))):\n",
    "    os.mkdir(dir_custom + str(min_instances))\n",
    "\n",
    "if min_instances == 0:\n",
    "    train_dir = os.path.join(base_dir, 'train')\n",
    "    validation_dir = os.path.join(base_dir, 'validation')\n",
    "    test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "else:    \n",
    "    train_dir = os.path.join(dir_custom + str(min_instances), 'train')\n",
    "    validation_dir = os.path.join(dir_custom + str(min_instances), 'validation')\n",
    "    test_dir = os.path.join(dir_custom + str(min_instances), 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for only required classes (e.g. classes which have atleast 100 classes)\n",
    "def get_required_classes(instances, total_classes):\n",
    "    for i in range(len(total_classes)):        \n",
    "        instances_length = os.listdir(original_dataset_dir + '/' + total_classes[i])        \n",
    "        if len(instances_length) >= instances or instances == 0:\n",
    "            required_classes.append(total_classes[i])\n",
    "            \n",
    "    return required_classes\n",
    "\n",
    "required_classes = []\n",
    "total_classes = os.listdir(original_dataset_dir) # getting all classes\n",
    "required_classes = get_required_classes(min_instances, total_classes)\n",
    "\n",
    "if not(os.path.exists(train_dir)):\n",
    "    os.mkdir(train_dir)\n",
    "    os.mkdir(validation_dir)\n",
    "    os.mkdir(test_dir)\n",
    "    \n",
    "    # Creating directories for classes within train, validation and testing\n",
    "    for i in range(len(required_classes)):\n",
    "       \n",
    "        train_data.append(os.path.join(train_dir, classes[i]))\n",
    "        os.mkdir(train_data[i])\n",
    "\n",
    "        validation_data.append(os.path.join(validation_dir, classes[i]))\n",
    "        os.mkdir(validation_data[i])\n",
    "\n",
    "        test_data.append(os.path.join(test_dir, classes[i]))\n",
    "        os.mkdir(test_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(required_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(required_classes)):\n",
    "    classname = original_dataset_dir + '/'+ required_classes[i]\n",
    "    fnames = os.listdir(classname)\n",
    "    length = len(fnames)\n",
    "              \n",
    "    train_per = round(length*.75)\n",
    "    val_per = round(length*0.15)\n",
    "    test_per = round(length*0.10)\n",
    "\n",
    "    print((i+1), required_classes[i], train_per, val_per, test_per)\n",
    "\n",
    "    for index in range(train_per):\n",
    "        src = os.path.join(classname, fnames[index])\n",
    "        dst = os.path.join(train_data[i], fnames[index])\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    for index in range(train_per, (train_per+val_per)):\n",
    "        src = os.path.join(classname, fnames[index])\n",
    "        dst = os.path.join(validation_data[i], fnames[index])\n",
    "        shutil.copyfile(src, dst)\n",
    "\n",
    "    for index in range((train_per+val_per), length):\n",
    "        src = os.path.join(classname, fnames[index])\n",
    "        dst = os.path.join(test_data[i], fnames[index])\n",
    "        shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = len(required_classes)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using pretrained model (Only in case of GPU)\n",
    "'''\n",
    "from keras.applications import VGG16\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "include_top=False,\n",
    "input_shape=(150, 150, 3))\n",
    "\n",
    "# add in first layer while designing CNN\n",
    "model.add(conv_base) # for using pretrained model\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 36, 36, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 17, 17, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 15, 15, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 102)               52326     \n",
      "=================================================================\n",
      "Total params: 3,504,934\n",
      "Trainable params: 3,504,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "metrics=['acc'])\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# code for data augmentation\n",
    "#train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "rotation_range=40,\n",
    "width_shift_range=0.2,\n",
    "height_shift_range=0.2,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=5,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=10,\n",
    "    class_mode='categorical')\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=500,\n",
    "    epochs=25,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('caltech_augmented.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
